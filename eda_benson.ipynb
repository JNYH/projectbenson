{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Benson"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aim\n",
    "\n",
    "- High Gala Participation Rate\n",
    "\n",
    "## How\n",
    "\n",
    "- Identifying High Traffic Volumes at Subway Entrances/Exits\n",
    " - By Day of Week\n",
    " - By Hour of Day\n",
    "\n",
    "\n",
    "\n",
    "- Identifying Target Audience (those more likely to be interested)\n",
    " - Identifying Stations with High Volumes of Non-Tourist Traffic (locals)\n",
    "     - By comparing station's weekend vs weekday traffic\n",
    "\n",
    " - [Demographic & Geographic Profiles](https://datausa.io/profile/geo/new-york-ny)\n",
    "     - Assume areas with more females more interested?\n",
    "     - Assume areas with higher income more likely to donate?\n",
    "     - Assume areas with younger demographics more interested?\n",
    "     - Assume areas with higher education level more interested?\n",
    "     - Assume areas with high employment in tech industry more interested?\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Data for January - June 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config InlineBackend.figure_format = 'svg'\n",
    "%matplotlib inline \n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kc/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3049: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "# 2017 Turnstile data from \"https://data.ny.gov/Transportation/Turnstile-Usage-Data-2017/v5y5-mwpb\"\n",
    "# Replace the path below with your own\n",
    "path = \"/Users/kc/OneDrive/Projects/projectbenson/data/data_2017.csv\"\n",
    "\n",
    "df = pd.read_csv(path, sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove whitespace from column names\n",
    "df.columns = df.columns.str.strip()\n",
    "\n",
    "# Drop irrelevant columns\n",
    "df.drop(columns=[\"Line Name\", \"Division\", \"Description\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate Date & Time into DateTime column DT\n",
    "df[\"DT\"] = df[['Date', 'Time']].apply(lambda x: ' '.join(x), axis=1)\n",
    "\n",
    "# Convert DT into DateTime format\n",
    "df[\"DT\"] = pd.to_datetime(df[\"DT\"], infer_datetime_format=True)\n",
    "\n",
    "# Concatenate C/A, Unit & SCP into 1 Unique Identifier Column\n",
    "df[\"ID\"] = df[[\"C/A\", \"Unit\", \"SCP\"]].apply(lambda x: ' '.join(x), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rearrange Columns\n",
    "df = df[[\"ID\", \"DT\", \"Station\", \"Entries\", \"Exits\"]]\n",
    "\n",
    "# Drop rows before and after 2017\n",
    "#df = df.loc[df[\"DT\"].dt.year == 2017]\n",
    "#df = df.loc[df[\"DT\"].dt.month < 6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort DT in descending order\n",
    "df.sort_values(by=['ID', 'DT'], ascending=[True, False], inplace=True)\n",
    "\n",
    "# Apply pd.Series.diff() on [\"Entries\"] and [\"Exits\"] within each [\"ID\"] group to obtain value of incremental change\n",
    "df['Entry_Diff'] = df.groupby(['ID'])['Entries'].apply(lambda x: abs(x.diff()))\n",
    "df['Exit_Diff'] = df.groupby(['ID'])['Exits'].apply(lambda x: abs(x.diff()))\n",
    "\n",
    "# Sum values of incremental change for [\"Entries\"] and [\"Exits\"] for overall Traffic within time interval\n",
    "df['Traffic'] = df[\"Entry_Diff\"] + df[\"Exit_Diff\"]\n",
    "\n",
    "# test\n",
    "# len(df.loc[df[\"ID\"] == \"A002 R051 02-00-00\"])\n",
    "# len(df.loc[df[\"ID\"] == \"A002 R051 02-00-01\"])\n",
    "# df.iloc[820:830]\n",
    "# df.iloc[1640:1650]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove outliers by filtering out values above 99th quantile\n",
    "\n",
    "f1 = df[\"Entry_Diff\"].quantile(0.99)\n",
    "df = df[df[\"Entry_Diff\"] < f1]\n",
    "\n",
    "f2 = df[\"Exit_Diff\"].quantile(0.99)\n",
    "df = df[df[\"Exit_Diff\"] < f2]\n",
    "\n",
    "f3 = df[\"Traffic\"].quantile(0.99)\n",
    "df = df[df[\"Traffic\"] < f3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mdata\u001b[m\u001b[m                  eda_benson.ipynb      test2.txt\r\n",
      "df.pickle             nyc_census_tracts.csv\r\n"
     ]
    }
   ],
   "source": [
    "# Pickle df so that above won't be necessary on each run\n",
    "# import pickle\n",
    "# with open('df.pickle', 'wb') as to_write:\n",
    "#     pickle.dump(df, to_write)\n",
    "    \n",
    "# Open df.pickle & assign to df\n",
    "# with open('df.pickle','rb') as read_file:\n",
    "#     df = pickle.load(read_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DT          Station       \n",
       "2017-07-28  34 ST-PENN STA    249843.0\n",
       "2017-10-20  34 ST-PENN STA    248981.0\n",
       "2017-12-21  34 ST-PENN STA    248519.0\n",
       "2017-04-26  34 ST-PENN STA    247727.0\n",
       "2017-11-03  34 ST-PENN STA    246450.0\n",
       "Name: Traffic, dtype: float64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Top Station by Day\n",
    "daily_sum = df.groupby([df[\"DT\"].dt.date, \"Station\"])[\"Traffic\"].sum().sort_values(ascending=False)\n",
    "daily_sum.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DT  Station       \n",
       "10  34 ST-PENN STA    6345268.0\n",
       "8   34 ST-PENN STA    6306490.0\n",
       "5   34 ST-PENN STA    6192585.0\n",
       "7   34 ST-PENN STA    6085899.0\n",
       "11  34 ST-PENN STA    6013257.0\n",
       "Name: Traffic, dtype: float64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Top Station by Month\n",
    "monthly_sum = df.groupby([df[\"DT\"].dt.month, \"Station\"])[\"Traffic\"].sum().sort_values(ascending=False)\n",
    "monthly_sum.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Station\n",
       "34 ST-PENN STA     62349545.0\n",
       "23 ST              44054767.0\n",
       "FULTON ST          41992155.0\n",
       "TIMES SQ-42 ST     38414250.0\n",
       "42 ST-PORT AUTH    37559305.0\n",
       "Name: Traffic, dtype: float64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Overall Top Monthly Station across all Stations\n",
    "yearly_sum = df.groupby([\"Station\"])[\"Traffic\"].sum().sort_values(ascending=False)\n",
    "yearly_sum.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Test for Outliers\n",
    "test_hist = df.loc[df[\"ID\"] == \"R260 R205 01-05-01\"][\"Traffic\"]\n",
    "\n",
    "plt.hist(test_hist)\n",
    "plt.show()\n",
    "\n",
    "###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "metis",
   "language": "python",
   "name": "metis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
